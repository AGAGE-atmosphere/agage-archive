import numpy as np
import xarray as xr
import pandas as pd
import warnings
from tempfile import NamedTemporaryFile
import json

from agage_archive.formatting import monthly_baseline
from agage_archive.config import open_data_file, data_file_path
from agage_archive.run import run_individual_instrument


def test_monthly_baseline():
    
    # Create a sample dataset
    time = pd.date_range("1991-01-01", "1991-12-31", freq="D")
    data = {"mf": (["time"], np.random.rand(len(time))),
            "mf_repeatability": (["time"], np.random.rand(len(time)))}
    ds = xr.Dataset(coords={"time": time}, data_vars=data)
    ds.mf.attrs["units"] = "1e-12"
    ds.attrs["version"] = "test"

    # Create a sample baseline dataset
    baseline_data = {"baseline": (["time"], np.random.choice([0, 1], size=len(time)))}
    ds_baseline = xr.Dataset(coords={"time": time}, data_vars=baseline_data)
    ds_baseline.attrs["baseline_flag"] = "Baseline Flag"

    ds_baseline_points = ds.where(ds_baseline.baseline == 1, drop=True)

    # Call the monthly_baseline function
    ds_monthly = monthly_baseline(ds, ds_baseline)

    # Check if the monthly mean is calculated correctly
    assert (ds_monthly.mf == ds_baseline_points.resample(time="1MS").mean().mf).all()

    # Check if the monthly standard deviation is calculated correctly
    expected_std = ds_baseline_points.mf.resample(time="1MS").std()
    assert (ds_monthly.mf_variability == expected_std).all()
    assert ds_monthly.mf_variability.attrs["long_name"] == "Monthly standard deviation of baseline mole fractions"
    assert ds_monthly.mf_variability.attrs["units"] == ds.mf.attrs["units"]

    # Check if the monthly standard error in mean is calculated correctly
    expected_se = ds_baseline_points.resample(time="1MS").mean().mf_repeatability / np.sqrt(ds_baseline_points.mf.resample(time="1MS").count())
    assert (ds_monthly.mf_repeatability == expected_se).all()
    assert ds_monthly.mf_repeatability.attrs["long_name"] == "Monthly standard error in mean of baseline mole fractions"
    assert ds_monthly.mf_repeatability.attrs["units"] == ds.mf.attrs["units"]

    # Check if the baseline flag is added correctly
    assert ds_monthly.attrs["baseline_flag"] == ds_baseline.attrs["baseline_flag"]

    # Check that a version number is present
    assert "version" in ds_monthly.attrs.keys()


def check_cf_compliance(dataset):
    """Tests the CF compliance of a dataset when written to netCDF format.
    Taken from openghg/tests/helpers/cfchecking.py module

    Args: 
        dataset: An xarray.Dataset
    Returns:
        bool: True if compliant
    """
    from cfchecker import CFChecker

    checker = CFChecker(debug=False, version="1.8")

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        with NamedTemporaryFile(suffix=".nc") as tmpfile:
            dataset.to_netcdf(tmpfile.name)
            result = checker.checker(file=tmpfile.name)

            fatal_global = result["global"]["FATAL"]
            error_global = result["global"]["ERROR"]

            fatal_vars = []
            error_vars = []
            for var in result["variables"].keys():
                fatal_vars.append(result["variables"][var]["FATAL"])
                error_vars.append(result["variables"][var]["ERROR"])
            
            if fatal_global or error_global or fatal_vars or error_vars:
                return False
            else:
                return True


def test_cf_compliance():
    """Test CF compliance of the NF3 MHD dataset, which is generated by the run_single_site function on the agage-test data
    
    Args:
        None
    
    """
    
    network = 'agage_test'
    sub_path = 'output/event'
    instrument = "GCMS-Medusa"
    site = "MHD" # data_release_schedule modified so that this is the only site
    species = "nf3"

    # Get current version number from attributes.json
    with open_data_file("attributes.json", this_repo=True) as f:
        attributes = json.load(f)
    version = attributes["version"]

    pth = data_file_path("",
                         network=network,
                         sub_path=sub_path)

    # Delete any files in pth
    for f in pth.rglob("*"):
        if f.is_file():
            f.unlink()

    run_individual_instrument(network=network,
                    instrument=instrument,
                    species=[species],
                    monthly=False,
                    verbose=False)
    
    with open_data_file(filename=f'{network.upper()}-{instrument.upper()}_{site}_{species}_{version}.nc',
                        network=network,
                        sub_path=sub_path + '/nf3',
                        ) as f:
        ds = xr.load_dataset(f)
    assert check_cf_compliance(dataset=ds)


